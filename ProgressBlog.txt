Fake News Detection
Progress Blog

Ioan Rowlands (ior2@aber.ac.uk

Got cross validation woring - not just using a method call i had to write it bit by bit in order to apply smote on the data. 

week 9(Mar 29th - April 5th)
Last meeting before Ester - No planned meeting for the break but Richard is only off 1 of 3 weeks so I can contact him in this time. Meetings may be possible if needed. 

I have under and over balenced the dataset this has produced much better results (up to 84% on the TF-IDF ANN classifer)

I have got SMOTE working - I struggled on this as I did not realise this was done on the numbers the articles are converted into rather than the figures producd after tfidf and word embeddings. 



week 8(Mar 21st - Mar 28th)
Week of mid project demo (got 74% so good for me)

Week 7( Mar 14th - Mar 20th)
Tues - I got the word embedding classification working!! - BIG - using code from a article Richard sent me this used heavily worked with a bit of adaptation for my dataset. 

Mon - I have got a Glove word embeddings model kinda working! Big deal. Will update mode tomorrow hopefully when 

Week 6 (Mar 7th - Mar 13th)
Looked into ELMO and BERT models. I have realised that my initial idea of comparing tfidf and word embeddings wont just be a different parameter to a classifier. This means my plan now is to compare the best results I have with tfidf with those from an ELMO model such as word2vec(gensim) and then a BURT model. 

More classifiers with tfidf:
I have implemented Decision Tree classification, Naive Bayes and Artifical Neural Network. 
Code now in repo. 

Meeting with Richard: basically this was not a great week a lot of my effor has been misplaced (regarding word embeddings)
To do: 
Word embeddings (if possible)
Preperation for mid project demonstration. 

I have began creating a presentation for the demonstration - this includes a diagram of te dataset demosnstraring the balence of the data. As well as a word cloud of the data with the most common words apprearing largest. 


Week 5 (Feb 28th - Mar 6th)
I have managed to convert the text to lowercase and worked out the possible issue with removing stopwords. 

I have been able to remove a list of stopwords. Although there is an interesting discussion over if this should be done. 

I have tokenized the words for the articles. This has been split into the fake and true news. 

I have split the data into train and test sets.

I have performed a Decision Tree Learner. This got an accuracy of 50% this is due to the fact I have been testing on a dataset of 7 items therefore I do not think this accuracy is relevant at all. But this was for proof of concept.

In all of this I have learnt a lot about handling the DataFrame data structure used by the pandas library. 

I have a meeting with Richard tomorrow. I have some practical work to show and proof of concept.  

Meeting notes: 
What I have is good. No complaints on where I am and what I have done. 
For next week I should be looking into a word embeddings implementation. 

1st Teams call with Mark Padley
For next meeting:
I need to be able to print some graphs as well as other metrics important when assesing the success of classification. 
Do some work on word embedings (word2vec) - possibly run a decision tree with tfidf and word embedings. 



Week 4 (Feb 21st - Feb 27th)
I created a flow chart of the plan based project we will complete with the key milestones of the project. 

I justified my choice in the dataset. 

Along with this I discussed the steps and methodology I will take in this project. This will be discussed with Richard. |Methodology looks good. Richard seems happy with it and the main thing is that there is interesting discussion. 

This week's target is to :
Complete pre-processing of the dataset. (began)
get a classifier (Naive Bayes) working in spyder as proof of concept 
Possibly get some graphs going. 

I have worked out that the dataset is tab separated values. This means using Pandas read_table function rather than the read_csv I am able to successfully read the file into Python. 



Week 3 (Feb 14th - Feb 20th)
Had a crisis on the dataset - but now I think I will stick with it and have two papers where the database was used. 

I could not find the papers so I emailed Richard - turns out you need to use google scholar. I found 2 good papers who have used the Kaggle dataset. 

I read a lot of papers now. At the start of week 4 I will write out my method and the steps I will take to complete the project. 



Week 2 (Feb 7 - Feb 14th)
Decided on datasets to use

Decided on project management strategy

Decided on Algorithms to use

Back up this with other work and reports from other research. 

Working on the project outline

Kaggle dataset has no pre-processing (good thing). 
Kaggle is already split into test and train(also good). 

Project outline is 75% completed (Wednesday)
By tomorrow project outline should be completed and Friday morning a review of the document can happen to submit it and move it from ‘draft’ to ‘released’.



Week 1 (Jan 31st - Feb 6th)
Beginning project. 

Not much work has been done this week. I have attended lectures and had my meeting with my project Supervisor. This meeting was productive in helping me better understand some of the areas of the project to focus on and other areas such as what is fake news? Not to dwell on this too much initially. 

I have begun this blog which I will update throughout the project for my own reflection. I have started the project outline document due on the 11th of February. 

This weekend I will set up some version control through GitHub where this can be a central storage point and version control.

I have set up a GitHub repository to store all work throughout the project. 
